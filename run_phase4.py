"""
Run Phase 4: Gradient-based Interpretability
============================================
Generates gradient-based explanations for sentiment predictions.
"""

import torch
from transformers import AutoTokenizer
from pathlib import Path
import sys

# Add src to path
sys.path.append(str(Path(__file__).parent))

from src.model import BERTSentimentClassifier
from src.gradient_explainer import GradientExplainer
from config import MODEL_NAME, NUM_LABELS, DEVICE


def main():
    """Run Phase 4 - Gradient-based Interpretability."""
    
    print("=" * 70)
    print("Phase 4: Gradient-based Interpretability")
    print("=" * 70)
    print()
    
    # ========================================================================
    # 1. Load Model and Tokenizer
    # ========================================================================
    
    print("üì¶ Loading model and tokenizer...")
    
    model_path = Path('models/model.pt')
    if not model_path.exists():
        print("‚ùå Error: Model not found!")
        print("   Please run Phase 1 first to train the model.")
        return
    
    # Load tokenizer
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    
    # Load model
    model = BERTSentimentClassifier(MODEL_NAME, NUM_LABELS)
    model.load_state_dict(torch.load(model_path, map_location=DEVICE))
    model.to(DEVICE)
    model.eval()
    
    print(f"‚úì Model loaded from {model_path}")
    print(f"‚úì Device: {DEVICE}")
    print()
    
    # ========================================================================
    # 2. Initialize Gradient Explainer
    # ========================================================================
    
    print("üîç Initializing Gradient Explainer...")
    explainer = GradientExplainer(model, tokenizer)
    print("‚úì Gradient explainer initialized")
    print()
    
    # ========================================================================
    # 3. Test Samples
    # ========================================================================
    
    test_samples = [
        "‡§Ø‡§π ‡§´‡§ø‡§≤‡•ç‡§Æ ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§•‡•Ä, ‡§Æ‡•Å‡§ù‡•á ‡§¨‡•á‡§π‡§¶ ‡§™‡§∏‡§Ç‡§¶ ‡§Ü‡§à‡•§",  # Positive
        "‡§ñ‡§æ‡§®‡§æ ‡§†‡•Ä‡§ï-‡§†‡§æ‡§ï ‡§•‡§æ, ‡§ï‡•Å‡§õ ‡§ñ‡§æ‡§∏ ‡§®‡§π‡•Ä‡§Ç‡•§",  # Neutral
        "‡§∏‡•á‡§µ‡§æ ‡§¨‡§π‡•Å‡§§ ‡§ñ‡§∞‡§æ‡§¨ ‡§•‡•Ä, ‡§¨‡§ø‡§≤‡•ç‡§ï‡•Å‡§≤ ‡§∏‡§Æ‡§Ø ‡§ï‡•Ä ‡§¨‡§∞‡•ç‡§¨‡§æ‡§¶‡•Ä‡•§"  # Negative
    ]
    
    # Create output directory
    output_dir = Path('outputs/phase4')
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"üìä Analyzing {len(test_samples)} test samples...")
    print()
    
    # ========================================================================
    # 4. Generate Explanations for Each Sample
    # ========================================================================
    
    for idx, text in enumerate(test_samples, 1):
        print(f"\n{'='*70}")
        print(f"Sample {idx}: {text}")
        print(f"{'='*70}\n")
        
        # ====================================================================
        # Method 1: Saliency Maps
        # ====================================================================
        
        print("üîπ Computing Saliency Map...")
        saliency_result = explainer.compute_saliency(text)
        
        print(f"   Prediction: {['Negative', 'Neutral', 'Positive'][saliency_result['predicted_class']]}")
        print(f"   Confidence: {saliency_result['probabilities'][saliency_result['predicted_class']]:.2%}")
        
        # Visualize
        explainer.plot_gradient_attribution(
            saliency_result,
            text,
            save_path=output_dir / f'sample_{idx}_saliency.png',
            merge_subwords=True
        )
        
        # ====================================================================
        # Method 2: Integrated Gradients
        # ====================================================================
        
        print("üîπ Computing Integrated Gradients...")
        ig_result = explainer.compute_integrated_gradients(text, n_steps=50)
        
        # Visualize
        explainer.plot_gradient_attribution(
            ig_result,
            text,
            save_path=output_dir / f'sample_{idx}_integrated_gradients.png',
            merge_subwords=True
        )
        
        # ====================================================================
        # Method 3: Gradient √ó Input
        # ====================================================================
        
        print("üîπ Computing Gradient √ó Input...")
        grad_input_result = explainer.compute_gradient_x_input(text)
        
        # Visualize
        explainer.plot_gradient_attribution(
            grad_input_result,
            text,
            save_path=output_dir / f'sample_{idx}_grad_x_input.png',
            merge_subwords=True
        )
        
        # ====================================================================
        # Comparison Plot
        # ====================================================================
        
        print("üîπ Creating comparison visualization...")
        results_dict = {
            'Saliency Map': saliency_result,
            'Integrated Gradients': ig_result,
            'Gradient √ó Input': grad_input_result
        }
        
        explainer.plot_method_comparison(
            results_dict,
            text,
            save_path=output_dir / f'sample_{idx}_comparison.png',
            merge_subwords=True
        )
        
        print(f"‚úì All visualizations saved for sample {idx}")
    
    # ========================================================================
    # 5. Summary
    # ========================================================================
    
    print("\n" + "="*70)
    print("‚úÖ Phase 4 Complete!")
    print("="*70)
    print(f"\nüìÅ Output directory: {output_dir.absolute()}")
    print(f"\nüìä Generated {len(test_samples) * 4} visualizations:")
    print("   ‚Ä¢ Saliency Maps - Shows gradient magnitude")
    print("   ‚Ä¢ Integrated Gradients - Integrates gradients from baseline")
    print("   ‚Ä¢ Gradient √ó Input - Combines gradients with embeddings")
    print("   ‚Ä¢ Comparison plots for each sample")
    print()
    print("üî¨ Key Insights:")
    print("   ‚Ä¢ Saliency: Simple and fast, shows instantaneous importance")
    print("   ‚Ä¢ Integrated Gradients: More stable, accounts for full path")
    print("   ‚Ä¢ Grad√óInput: Balances gradient and input magnitude")
    print()
    print("Next: Phase 5 - Counterfactual Analysis")
    print()


if __name__ == "__main__":
    main()

